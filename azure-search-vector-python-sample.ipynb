{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search Code Sample with Azure OpenAI\n",
    "This code demonstrates how to use Azure Cognitive Search with OpenAI and Azure Python SDK\n",
    "## Prerequisites\n",
    "To run the code, install the following packages. Please note that the `pip install azure-search-documents==11.4.0a20230509004` is currently using the Dev Feed. For instructions on how to connect to the dev feed, please visit [Azure-Python-SDK Azure Search Documents Dev Feed](https://dev.azure.com/azure-sdk/public/_artifacts/feed/azure-sdk-for-python/connect/pip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-search-documents --pre\n",
    "! pip install openai\n",
    "! pip install python-dotenv\n",
    "! pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai[datalib]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m openai\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_ENDPOINT\u001b[39m\u001b[39m\"\u001b[39m)  \n\u001b[0;32m     34\u001b[0m openai\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_VERSION\u001b[39m\u001b[39m\"\u001b[39m)  \n\u001b[1;32m---> 35\u001b[0m credential \u001b[39m=\u001b[39m AzureKeyCredential(key)\n\u001b[0;32m     36\u001b[0m \u001b[39m# Form Recognizer init\u001b[39;00m\n\u001b[0;32m     37\u001b[0m formrecognizer_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mAZURE_FORMRECOGNIZER_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'key' is not defined"
     ]
    }
   ],
   "source": [
    "# Import required libraries  \n",
    "import os  \n",
    "import json  \n",
    "import openai  \n",
    "from dotenv import load_dotenv  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmConfiguration,  \n",
    ")  \n",
    "  \n",
    "# Configure environment variables  \n",
    "load_dotenv()  \n",
    "# OpenAI init\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\") or \"gpt35-turbo-test\" \n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"OPENAI_ENDPOINT\")  \n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")  \n",
    "# Form Recognizer init\n",
    "formrecognizer_key = os.getenv(\"AZURE_FORMRECOGNIZER_KEY\")\n",
    "formrecognizer_creds = AzureKeyCredential(formrecognizer_key)\n",
    "formrecognizerservice = os.getenv(\"AZURE_FORMRECOGNIZER_SERVICE\")\n",
    "# Azure search init\n",
    "searchservice= os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")  \n",
    "search_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")  \n",
    "search_credential = AzureKeyCredential(search_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT uses a particular set of tokens to indicate turns in conversations\n",
    "prompt_prefix = \"\"\"<|im_start|>system\n",
    "Assistant helps the company employees with their questions on company policies, roles. \n",
    "Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question. \n",
    "Each source file has a name followed by colon and by source page  followed by second colon and the actual information, always include the source name for each fact you use in the response. Use square brakets to reference the source file and source page, separate souefile and sourcepage by colon, e.g. [role_library.pdf:role_library-6.pdf]. Don't combine sources, list each source separately, e.g. [role_library.pdf:role_library-1.pdf][role_library.pdf:role_library-6.pdf].\n",
    "\n",
    "Sources:\n",
    "{sources}\n",
    "\n",
    "<|im_end|>\"\"\"\n",
    "\n",
    "turn_prefix = \"\"\"\n",
    "<|im_start|>user\n",
    "\"\"\"\n",
    "\n",
    "turn_suffix = \"\"\"\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "prompt_history = turn_prefix\n",
    "\n",
    "history = []\n",
    "\n",
    "summary_prompt_template = \"\"\"Below is a summary of the conversation so far, and a new question asked by the user that needs to be answered by searching in a knowledge base. Generate a search query based on the conversation and the new question. Source names are not good search terms to include in the search query.\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Search query:\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your search index\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=search_credential)\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "#    SearchableField(name=\"title\", type=SearchFieldDataType.String,\n",
    "#                    searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String,\n",
    "                    searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                    filterable=True, searchable=True, retrievable=True),\n",
    "    SimpleField(name=\"sourcepage\", type=\"Edm.String\", filterable=True, facetable=True),\n",
    "    SimpleField(name=\"sourcefile\", type=\"Edm.String\", filterable=True, facetable=True),\n",
    "#    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "#                searchable=True, dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        VectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            hnsw_parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 1000,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "#        title_field=SemanticField(field_name=\"title\"),\n",
    "        prioritized_keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PDF parse functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import html\n",
    "\n",
    "def table_to_html(table):\n",
    "    table_html = \"<table>\"\n",
    "    rows = [sorted([cell for cell in table.cells if cell.row_index == i], key=lambda cell: cell.column_index) for i in range(table.row_count)]\n",
    "    for row_cells in rows:\n",
    "        table_html += \"<tr>\"\n",
    "        for cell in row_cells:\n",
    "            tag = \"th\" if (cell.kind == \"columnHeader\" or cell.kind == \"rowHeader\") else \"td\"\n",
    "            cell_spans = \"\"\n",
    "            if cell.column_span > 1: cell_spans += f\" colSpan={cell.column_span}\"\n",
    "            if cell.row_span > 1: cell_spans += f\" rowSpan={cell.row_span}\"\n",
    "            table_html += f\"<{tag}{cell_spans}>{html.escape(cell.content)}</{tag}>\"\n",
    "        table_html +=\"</tr>\"\n",
    "    table_html += \"</table>\"\n",
    "    return table_html\n",
    "\n",
    "def get_document_text(filename):\n",
    "    offset = 0\n",
    "    page_map = []\n",
    "    print(f\"Extracting text from '{filename}' using Azure Form Recognizer\")\n",
    "\n",
    "    form_recognizer_client = DocumentAnalysisClient(endpoint=f\"https://{formrecognizerservice}.cognitiveservices.azure.com/\", credential=formrecognizer_creds, headers={\"x-ms-useragent\": \"azure-search-chat-demo/1.0.0\"})\n",
    "    with open(filename, \"rb\") as f:\n",
    "        poller = form_recognizer_client.begin_analyze_document(\"prebuilt-layout\", document = f)\n",
    "    form_recognizer_results = poller.result()\n",
    "\n",
    "    for page_num, page in enumerate(form_recognizer_results.pages):\n",
    "        tables_on_page = [table for table in form_recognizer_results.tables if table.bounding_regions[0].page_number == page_num + 1]\n",
    "\n",
    "        # mark all positions of the table spans in the page\n",
    "        page_offset = page.spans[0].offset\n",
    "        page_length = page.spans[0].length\n",
    "        table_chars = [-1]*page_length\n",
    "        for table_id, table in enumerate(tables_on_page):\n",
    "            for span in table.spans:\n",
    "                # replace all table spans with \"table_id\" in table_chars array\n",
    "                for i in range(span.length):\n",
    "                    idx = span.offset - page_offset + i\n",
    "                    if idx >=0 and idx < page_length:\n",
    "                        table_chars[idx] = table_id\n",
    "\n",
    "        # build page text by replacing charcters in table spans with table html\n",
    "        page_text = \"\"\n",
    "        added_tables = set()\n",
    "        for idx, table_id in enumerate(table_chars):\n",
    "            if table_id == -1:\n",
    "                page_text += form_recognizer_results.content[page_offset + idx]\n",
    "            elif not table_id in added_tables:\n",
    "                page_text += table_to_html(tables_on_page[table_id])\n",
    "                added_tables.add(table_id)\n",
    "\n",
    "        page_text += \" \"\n",
    "        page_map.append((page_num, offset, page_text))\n",
    "        offset += len(page_text)\n",
    "\n",
    "    return page_map\n",
    "\n",
    "for filename in glob.glob(\".\\data\\*\"):\n",
    "\n",
    "page_map = get_document_text(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions to upload cognitive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import *\n",
    "from azure.search.documents import SearchClient\n",
    "import openai \n",
    "import re\n",
    "\n",
    "def blob_name_from_file_page(filename, page = 0):\n",
    "    if os.path.splitext(filename)[1].lower() == \".pdf\":\n",
    "        return os.path.splitext(os.path.basename(filename))[0] + f\"-{page}\" + \".pdf\"\n",
    "    else:\n",
    "        return os.path.basename(filename)\n",
    "    \n",
    "def create_sections(filename, page_map):\n",
    "    for page in page_map:\n",
    "        pagenum=page[0]+1\n",
    "        yield {\n",
    "            \"id\": re.sub(\"[^0-9a-zA-Z_-]\",\"_\",f\"{filename}-{pagenum}\"),\n",
    "            \"content\": page[2],\n",
    "            \"category\": \"test01\",\n",
    "            \"sourcepage\": blob_name_from_file_page(filename, pagenum),\n",
    "            \"sourcefile\": filename\n",
    "        }\n",
    "\n",
    "def index_sections(filename, sections):\n",
    "    print(f\"Indexing sections from '{filename}' into search index '{index_name}'\")\n",
    "    search_client = SearchClient(endpoint=f\"https://{searchservice}.search.windows.net/\",\n",
    "                                    index_name=index_name,\n",
    "                                    credential=search_credential)\n",
    "    def generate_embeddings(text):\n",
    "        response = openai.Embedding.create(\n",
    "            input=text, engine=\"ada-embed-test\")\n",
    "        embeddings = response['data'][0]['embedding']\n",
    "        return embeddings\n",
    "\n",
    "    i = 0\n",
    "    batch = []\n",
    "    for s in sections:\n",
    "        content = s['content']\n",
    "        content_embeddings = generate_embeddings(content)\n",
    "        s['contentVector'] = content_embeddings\n",
    "        batch.append(s)\n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            results = search_client.upload_documents(documents=batch)\n",
    "            succeeded = sum([1 for r in results if r.succeeded])\n",
    "            print(f\"\\tIndexed {len(results)} sections, {succeeded} succeeded\")\n",
    "            batch = []\n",
    "\n",
    "    if len(batch) > 0:\n",
    "        results = search_client.upload_documents(documents=batch)\n",
    "        succeeded = sum([1 for r in results if r.succeeded])\n",
    "        print(f\"\\tIndexed {len(results)} sections, {succeeded} succeeded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for filename in glob.glob(\".\\data\\*\"):\n",
    "    print(f\"Processing '{filename}'\")\n",
    "    page_map = get_document_text(filename)\n",
    "    sections = create_sections(os.path.basename(filename), page_map)\n",
    "    index_sections(os.path.basename(filename), sections)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SearchClient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m exclude_category \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      8\u001b[0m query \u001b[39m=\u001b[39m user_input\n\u001b[1;32m---> 10\u001b[0m search_client \u001b[39m=\u001b[39m SearchClient(service_endpoint, index_name, AzureKeyCredential(key))  \n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_embeddings\u001b[39m(text):\n\u001b[0;32m     13\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mEmbedding\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m     14\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mtext, engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mada-embed-test\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SearchClient' is not defined"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search\n",
    "#user_input = \"What is the difference in responsibilities between a Vice President of Human Resources and Manager of Human Resources\"  \n",
    "user_input = \"What are responsibilities of a Vice President of Human Resources and Manager of Human Resources\"  \n",
    "\n",
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "query = user_input\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))  \n",
    "\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=\"ada-embed-test\")\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "r = search_client.search(  \n",
    "    search_text=\"\",  \n",
    "    vector=generate_embeddings(query), \n",
    "    top_k=6, \n",
    "    vector_fields=\"contentVector\",  \n",
    "    select=[\"content\", \"sourcefile\", \"sourcepage\"] \n",
    ")  \n",
    "\n",
    "results = [doc['sourcefile'] + \": \"+doc['sourcepage'] + \": \" + doc['content'].replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r]\n",
    "\n",
    "content = \"\\n\".join(results)\n",
    "\n",
    "prompt = prompt_prefix.format(sources=content) + prompt_history + user_input + turn_suffix\n",
    "\n",
    "completion = openai.Completion.create(\n",
    "    engine=AZURE_OPENAI_CHATGPT_DEPLOYMENT, \n",
    "    prompt=prompt, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024,\n",
    "    stop=[\"<|im_end|>\", \"<|im_start|>\"])\n",
    "\n",
    "prompt_history += user_input + turn_suffix + completion.choices[0].text + \"\\n<|im_end|>\" + turn_prefix\n",
    "history.append(\"user: \" + user_input)\n",
    "history.append(\"assistant: \" + completion.choices[0].text)\n",
    "\n",
    "print(\"\\n-------------------\\n\".join(history))\n",
    "print(\"\\n-------------------\\nSource:\\n\" + prompt)\n",
    "print(\"\\n-------------------\\nPrompt:\\n\" + prompt)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
